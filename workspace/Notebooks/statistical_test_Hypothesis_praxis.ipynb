{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -*- coding: utf-8 -*-\n",
    "# library imports\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4e0c1",
   "metadata": {},
   "source": [
    "# --- Data Extraction from Table 13 ---\n",
    "# This data is taken directly from Table 13 in the praxis document.\n",
    "# N/A values from the table are excluded from the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe2ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Year</th>\n",
       "      <th>Feature Selection</th>\n",
       "      <th>ML Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catillo et al.</td>\n",
       "      <td>2020</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Deep Autoencoder</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>5.000000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saeful Fitni and Ramli</td>\n",
       "      <td>2020</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Ensemble (Voting)</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>2.596270e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karatas et al.</td>\n",
       "      <td>2020</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kim et al.</td>\n",
       "      <td>2020</td>\n",
       "      <td>Manual</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peng et al.</td>\n",
       "      <td>2019</td>\n",
       "      <td>Manual</td>\n",
       "      <td>LSTM &amp; Attention Mechanism</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>6.700000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Darko</td>\n",
       "      <td>2023</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>BERT</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.992200</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>1.000000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zhao et al.</td>\n",
       "      <td>2020</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Deep Autoencoder</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>2.100000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Proposed 1</td>\n",
       "      <td>2025</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>AutoGluon subset 1</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>3.300000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Proposed 2</td>\n",
       "      <td>2025</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>AutoGluon subset 2</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>2.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Proposed 3</td>\n",
       "      <td>2025</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Azure AutoML subset 1</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>2.800000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Proposed 4</td>\n",
       "      <td>2025</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Azure AutoML subset 2</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>2.800000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Proposed 5</td>\n",
       "      <td>2025</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>AWS AutoPilot subset 1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.600000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Proposed 6</td>\n",
       "      <td>2025</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>AWS AutoPilot subset 2</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.800000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Study  Year Feature Selection  \\\n",
       "0           Catillo et al.  2020            Manual   \n",
       "1   Saeful Fitni and Ramli  2020            Manual   \n",
       "2           Karatas et al.  2020            Manual   \n",
       "3               Kim et al.  2020            Manual   \n",
       "4              Peng et al.  2019            Manual   \n",
       "5                    Darko  2023         Automatic   \n",
       "6              Zhao et al.  2020         Automatic   \n",
       "7               Proposed 1  2025         Automatic   \n",
       "8               Proposed 2  2025         Automatic   \n",
       "9               Proposed 3  2025         Automatic   \n",
       "10              Proposed 4  2025         Automatic   \n",
       "11              Proposed 5  2025         Automatic   \n",
       "12              Proposed 6  2025         Automatic   \n",
       "\n",
       "                     ML Method  Accuracy        F1  Precision    Recall  \\\n",
       "0             Deep Autoencoder  0.992000       NaN   0.950000  0.989000   \n",
       "1            Ensemble (Voting)  0.988000  0.979000   0.988000  0.971000   \n",
       "2                     Adaboost  0.996900  0.997000   0.997000  0.997000   \n",
       "3                          CNN  0.999900       NaN   0.818000  0.823000   \n",
       "4   LSTM & Attention Mechanism  0.962000  0.930000   0.960000  0.960000   \n",
       "5                         BERT  0.998200  0.992200   0.986300  0.998300   \n",
       "6             Deep Autoencoder  0.979000  0.980000   0.980000  0.980000   \n",
       "7           AutoGluon subset 1  0.999993  0.999993   0.999993  0.999993   \n",
       "8           AutoGluon subset 2  0.999997  0.999997   0.999997  0.999997   \n",
       "9        Azure AutoML subset 1  0.999998  0.999998   0.999998  0.999998   \n",
       "10       Azure AutoML subset 2  0.999997  0.999997   0.999997  0.999997   \n",
       "11      AWS AutoPilot subset 1  1.000000  1.000000   1.000000  1.000000   \n",
       "12      AWS AutoPilot subset 2  0.999995  0.999996   0.999996  0.999995   \n",
       "\n",
       "             FPR  \n",
       "0   5.000000e-03  \n",
       "1   2.596270e-02  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4   6.700000e-03  \n",
       "5   1.000000e-03  \n",
       "6   2.100000e-02  \n",
       "7   3.300000e-07  \n",
       "8   2.000000e-08  \n",
       "9   2.800000e-07  \n",
       "10  2.800000e-07  \n",
       "11  4.600000e-07  \n",
       "12  1.800000e-07  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visulization of the data table\n",
    "# This data is taken directly from Table 13 in the praxis document.\n",
    "# N/A values from the table are excluded from the lists.    \n",
    "\n",
    "csv_data = \"\"\"\n",
    "Study,Year,Feature Selection,ML Method,Accuracy,F1,Precision,Recall,FPR\n",
    "Catillo et al.,2020,Manual,Deep Autoencoder,0.992,NA,0.950,0.989,0.00500000\n",
    "Saeful Fitni and Ramli,2020,Manual,Ensemble (Voting),0.988,0.979,0.988,0.971,0.0259627\n",
    "Karatas et al.,2020,Manual,Adaboost,0.9969,0.997,0.997,0.997,NA\n",
    "Kim et al.,2020,Manual,CNN,0.9999,NA,0.818,0.823,NA\n",
    "Peng et al.,2019,Manual,LSTM & Attention Mechanism,0.962,0.930,0.960,0.960,0.00670\n",
    "Darko,2023,Automatic,BERT,0.9982,0.9922,0.9863,0.9983,0.00100000\n",
    "Zhao et al.,2020,Automatic,Deep Autoencoder,0.979,0.980,0.980,0.980,0.02100000\n",
    "Proposed 1,2025,Automatic,AutoGluon subset 1,0.999993,0.9999928,0.9999929,0.9999928,0.00000033\n",
    "Proposed 2,2025,Automatic,AutoGluon subset 2,0.9999966,0.9999967,0.9999967,0.9999967,0.00000002\n",
    "Proposed 3,2025,Automatic,Azure AutoML subset 1,0.999998,0.999998,0.999998,0.999998,0.00000028\n",
    "Proposed 4,2025,Automatic,Azure AutoML subset 2,0.999997,0.999997,0.999997,0.999997,0.00000028\n",
    "Proposed 5,2025,Automatic,AWS AutoPilot subset 1,0.9999998,0.9999998,0.9999998,0.9999998,0.00000046\n",
    "Proposed 6,2025,Automatic,AWS AutoPilot subset 2,0.9999954,0.9999957,0.9999963,0.9999954,0.00000018\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06b99d",
   "metadata": {},
   "source": [
    "# Group 1: The 6 Proposed AutoML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the columns to lists\n",
    "proposed_accuracy = [0.9999930, 0.9999966, 0.9999980, 0.9999970, 0.9999998, 0.9999954]\n",
    "proposed_f1 = [0.9999928, 0.9999967, 0.9999980, 0.9999970, 0.9999998, 0.9999957]\n",
    "proposed_precision = [0.9999929, 0.9999967, 0.9999980, 0.9999970, 0.9999998, 0.9999963]\n",
    "proposed_recall = [0.9999928, 0.9999967, 0.9999980, 0.9999970, 0.9999998, 0.9999954]\n",
    "proposed_fpr = [0.00000033, 0.00000002, 0.00000028, 0.00000028, 0.00000046, 0.00000018]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d0db4",
   "metadata": {},
   "source": [
    "# Group 2: The 7 Benchmark Studies from Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e219c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 2: Benchmark Models from Praxis Document\n",
    "benchmark_accuracy = [0.9920, 0.9880, 0.9969, 0.9999, 0.9620, 0.9982, 0.9790]\n",
    "benchmark_f1 = [0.9790, 0.9970, 0.9300, 0.9922, 0.9800]  # n=5\n",
    "benchmark_precision = [0.9500, 0.9880, 0.9970, 0.8180, 0.9600, 0.9863, 0.9800]\n",
    "benchmark_recall = [0.9890, 0.9710, 0.9970, 0.8230, 0.9600, 0.9983, 0.9800]\n",
    "benchmark_fpr = [0.0050, 0.0010, 0.0210, 0.00670, 0.0259627]  # n=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ad161",
   "metadata": {},
   "source": [
    "# --- Performing the T-Tests ---\n",
    "```\n",
    ">  Based on normalization test/outcome which the p-value is less than 0.05 I used Welch's t-test (equal_var=False) as it's more reliable for groups with unequal sizes and variances.\n",
    "> I used a one-tailed test (alternative='greater' or 'less') to directly\n",
    ">  I tested the hypotheses H1 and H2 only.\n",
    "> H3 is not scoped as I did not track bechnmark time of training and process. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576e4d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0c9b2ef",
   "metadata": {},
   "source": [
    "# H1 Test: Is the proposed AutoML group's performance SIGNIFICANTLY GREATER than Benchmark group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39be0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-tests for each metric\n",
    "# H1: Proposed group's performance is significantly greater than the benchmark group.\n",
    "# H2: Proposed group's performance is significantly less than the benchmark group.\n",
    "# H0: There is no significant difference between the two groups.\n",
    "# We use Welch's t-test (equal_var=False) as it's more reliable for groups\n",
    "# with unequal sizes and variances.\n",
    "# We use a one-tailed test (alternative='greater' or 'less') to directly\n",
    "# test the hypotheses H1 and H2.\n",
    "# Group 1: The 6 Proposed AutoML Models\n",
    "# Group 2: The Benchmark AutoML Models\n",
    "t_stat_acc, p_val_acc = stats.ttest_ind(proposed_accuracy, benchmark_accuracy, equal_var=False, alternative='greater')\n",
    "t_stat_f1, p_val_f1 = stats.ttest_ind(proposed_f1, benchmark_f1, equal_var=False, alternative='greater')\n",
    "t_stat_prec, p_val_prec = stats.ttest_ind(proposed_precision, benchmark_precision, equal_var=False, alternative='greater')\n",
    "t_stat_recall, p_val_recall = stats.ttest_ind(proposed_recall, benchmark_recall, equal_var=False, alternative='greater')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f94a0",
   "metadata": {},
   "source": [
    "# H2 Test: Is the proposed group's FPR SIGNIFICANTLY LESS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37435c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2 Test: Is the proposed group's performance SIGNIFICANTLY LESS?\n",
    "t_stat_fpr, p_val_fpr = stats.ttest_ind(proposed_fpr, benchmark_fpr, equal_var=False, alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ececde4",
   "metadata": {},
   "source": [
    "# --- Displaying the Results ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cc3227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Statistical Validation of Hypotheses ---\n",
      "\n",
      "--- H1: Performance Improvement (Higher is Better) ---\n",
      "Accuracy:       t-statistic = 2.346, p-value = 0.0287\n",
      "F1-Score:       t-statistic = 2.043, p-value = 0.0553\n",
      "Precision:      t-statistic = 1.946, p-value = 0.0498\n",
      "Recall:         t-statistic = 1.721, p-value = 0.0680\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"--- Statistical Validation of Hypotheses ---\")\n",
    "print(\"\\n--- H1: Performance Improvement (Higher is Better) ---\")\n",
    "print(f\"Accuracy:       t-statistic = {t_stat_acc:.3f}, p-value = {p_val_acc:.4f}\")\n",
    "print(f\"F1-Score:       t-statistic = {t_stat_f1:.3f}, p-value = {p_val_f1:.4f}\")\n",
    "print(f\"Precision:      t-statistic = {t_stat_prec:.3f}, p-value = {p_val_prec:.4f}\")\n",
    "print(f\"Recall:         t-statistic = {t_stat_recall:.3f}, p-value = {p_val_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35874943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- H2: False Positive Rate Reduction (Lower is Better) ---\n",
      "FPR:            t-statistic = -2.451, p-value = 0.0352\n"
     ]
    }
   ],
   "source": [
    "# H2: False Positive Rate Reduction (Lower is Better)\n",
    "print(\"\\n--- H2: False Positive Rate Reduction (Lower is Better) ---\")\n",
    "print(f\"FPR:            t-statistic = {t_stat_fpr:.3f}, p-value = {p_val_fpr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgan",
   "language": "python",
   "name": "pgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
